{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latin-soviet",
   "metadata": {},
   "source": [
    "### Need to read 311 file, which is 7GB. To make it useful only need to read minimal number of columns and save it as a short version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_311 = '311_Service_Requests_from_2010_to_Present.csv'\n",
    "print(os.path.getsize(fname_311)/1024/1024/1024 , \"GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(processes=False)\n",
    "client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could not read 7GB file using pandas, found package 'dask' which provides multithreaded capabilities\n",
    "start = time.time()\n",
    "cols_to_read = [0,1,5,8,16,25]\n",
    "# dates = ['Created Date'] \n",
    "# types = {'Unique Key':object, 'Incident Zip':object}\n",
    "types = {'Unique Key':object, 'Incident Zip':object}\n",
    "dask_df = dd.read_csv(fname_311, usecols=cols_to_read, dtype = types)\n",
    "end = time.time()\n",
    "print(\"Read csv with dask: \",(end-start),\"sec\")\n",
    "dask_df = dask_df.compute(scheduler='threads')\n",
    "end1 = time.time()\n",
    "print(\"Computed csv with dask: \",(end1-end),\"sec\")\n",
    "dask_df.to_csv(\"311_short.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
